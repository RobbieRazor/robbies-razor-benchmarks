{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TPCA / FPCA Demonstration (Minimal)\n",
        "\n",
        "This notebook provides a **small, illustrative** example of how to measure:\n",
        "\n",
        "- **TPCA** — Tokens Per Correct Answer\n",
        "- **FPCA (proxy)** — Latency (ms) Per Correct Answer\n",
        "\n",
        "under Robbie’s Razor evaluation logic.\n",
        "\n",
        "**Scope note:** This is a demonstration only (not a benchmark leaderboard). The authoritative evaluation surfaces are the unit tests and benchmark scripts in the repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "We add the repo root to `sys.path` so imports work when running from the `notebooks/` directory,\n",
        "then import the canonical `RazorMemoryBank` reference implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, time\n",
        "\n",
        "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "\n",
        "from src.razor.memory_bank import RazorMemoryBank\n",
        "\n",
        "print(\"Repo root:\", repo_root)\n",
        "print(\"Imported:\", RazorMemoryBank)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definitions\n",
        "\n",
        "We compute TPCA and an FPCA-like proxy using latency (ms) instead of FLOPs.\n",
        "\n",
        "- **TPCA** = total output tokens / number of correct answers\n",
        "- **FPCA (latency proxy)** = total latency ms / number of correct answers\n",
        "\n",
        "Token counting here uses a deterministic proxy: ~4 characters per token.\n",
        "This avoids external dependencies while still providing a stable ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def token_proxy(text: str) -> int:\n",
        "    \"\"\"Deterministic proxy: tokens ~= max(1, ceil(len(text)/4)).\"\"\"\n",
        "    text = text or \"\"\n",
        "    return max(1, (len(text) + 3) // 4)\n",
        "\n",
        "\n",
        "def tpca(num_correct: int, total_tokens: int):\n",
        "    return None if num_correct == 0 else total_tokens / num_correct\n",
        "\n",
        "\n",
        "def fpca_latency(num_correct: int, total_ms: float):\n",
        "    return None if num_correct == 0 else total_ms / num_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario\n",
        "\n",
        "We simulate a workload with repeated queries. The memory bank short-circuits repeated work.\n",
        "\n",
        "### Baseline\n",
        "- Always \"infer\" (we simulate inference latency)\n",
        "- Always output a fixed answer length\n",
        "\n",
        "### Razor (Memory Gate)\n",
        "- Check memory first\n",
        "- If hit (high-confidence), return immediately (near-zero latency / tokens)\n",
        "- Otherwise \"infer\" once, then store result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthetic workload (repeats)\n",
        "queries = [\n",
        "    \"What is 17 * 23?\",\n",
        "    \"What is 17 * 23?\",\n",
        "    \"What is the capital of France?\",\n",
        "    \"What is 17 * 23?\",\n",
        "    \"What is the capital of France?\",\n",
        "    \"What is 2 + 2?\",\n",
        "    \"What is 2 + 2?\",\n",
        "]\n",
        "\n",
        "# Ground truth mapping (simple correctness)\n",
        "truth = {\n",
        "    \"What is 17 * 23?\": \"391\",\n",
        "    \"What is the capital of France?\": \"Paris\",\n",
        "    \"What is 2 + 2?\": \"4\",\n",
        "}\n",
        "\n",
        "# Simulated inference output\n",
        "def simulated_model_output(q: str) -> str:\n",
        "    # Return a short correct answer (make verbose to see TPCA worsen)\n",
        "    return truth[q]\n",
        "\n",
        "# Simulated inference latency (ms)\n",
        "INFER_MS = 250\n",
        "\n",
        "print(\"Workload size:\", len(queries))\n",
        "print(\"Unique queries:\", len(set(queries)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run: Baseline (always infer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_total_tokens = 0\n",
        "baseline_total_ms = 0\n",
        "baseline_correct = 0\n",
        "\n",
        "for q in queries:\n",
        "    baseline_total_ms += INFER_MS\n",
        "    out = simulated_model_output(q)\n",
        "    baseline_total_tokens += token_proxy(out)\n",
        "    if out == truth[q]:\n",
        "        baseline_correct += 1\n",
        "\n",
        "baseline_tpca = tpca(baseline_correct, baseline_total_tokens)\n",
        "baseline_fpca = fpca_latency(baseline_correct, baseline_total_ms)\n",
        "\n",
        "print(\"Baseline correct:\", baseline_correct)\n",
        "print(\"Baseline total tokens:\", baseline_total_tokens)\n",
        "print(\"Baseline total ms:\", baseline_total_ms)\n",
        "print(\"Baseline TPCA:\", baseline_tpca)\n",
        "print(\"Baseline FPCA (ms/correct):\", baseline_fpca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run: Razor Memory Gate (R4-style short-circuit)\n",
        "\n",
        "Memory hits incur near-zero incremental cost; misses incur inference cost once then store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bank = RazorMemoryBank(capacity=1000, stability_threshold=0.95)\n",
        "\n",
        "razor_total_tokens = 0\n",
        "razor_total_ms = 0\n",
        "razor_correct = 0\n",
        "razor_hits = 0\n",
        "razor_misses = 0\n",
        "\n",
        "for q in queries:\n",
        "    cached, conf = bank.retrieve(q)\n",
        "    if cached is not None and conf >= 0.95:\n",
        "        razor_hits += 1\n",
        "        out = cached\n",
        "    else:\n",
        "        razor_misses += 1\n",
        "        razor_total_ms += INFER_MS\n",
        "        out = simulated_model_output(q)\n",
        "        razor_total_tokens += token_proxy(out)\n",
        "        # Store only if confidence passes the bank's stability threshold\n",
        "        bank.store(q, out, confidence=0.99)\n",
        "\n",
        "    if out == truth[q]:\n",
        "        razor_correct += 1\n",
        "\n",
        "hit_rate = razor_hits / len(queries)\n",
        "razor_tpca = tpca(razor_correct, razor_total_tokens)\n",
        "razor_fpca = fpca_latency(razor_correct, razor_total_ms)\n",
        "\n",
        "print(\"Razor correct:\", razor_correct)\n",
        "print(\"Razor hits:\", razor_hits)\n",
        "print(\"Razor misses:\", razor_misses)\n",
        "print(\"Hit rate:\", f\"{hit_rate:.2%}\")\n",
        "print(\"Razor total tokens (misses only):\", razor_total_tokens)\n",
        "print(\"Razor total ms (misses only):\", razor_total_ms)\n",
        "print(\"Razor TPCA:\", razor_tpca)\n",
        "print(\"Razor FPCA (ms/correct):\", razor_fpca)\n",
        "\n",
        "try:\n",
        "    print(\"Memory stats:\", bank.get_stats())\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation\n",
        "\n",
        "This toy example shows the basic mechanism behind efficiency:\n",
        "\n",
        "- If a workload contains repetition, **memory hits** can skip expensive inference.\n",
        "- That reduces both token-related costs (TPCA) and compute/latency proxies (FPCA).\n",
        "\n",
        "In real systems, savings depend on:\n",
        "- repetition rate\n",
        "- verification strategy\n",
        "- how memory keys are canonicalized\n",
        "- where the gate sits (before inference)\n",
        "\n",
        "For formal evaluation, use the benchmark scripts and unit tests in this repository."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
