{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Razor Diffusion Plot + Hex Facet Index (v1)\n",
        "\n",
        "This notebook:\n",
        "\n",
        "- Loads a JSONL run (`../runs/demo.jsonl`)\n",
        "- Normalizes fields required by the RDM evaluator\n",
        "- Computes RDM / RDM* for the run\n",
        "- Evaluates an adversarial cheating baseline\n",
        "- Plots instantaneous semantic drift per unit cost\n",
        "- Computes Hex Facet Index metrics (facet IDs, leap rate, Lattice Stability Score)\n",
        "- Visualizes facet occupancy as a hexbin density map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure imports work when running from /notebooks\n",
        "import os, sys\n",
        "\n",
        "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "\n",
        "print(\"Repo root:\", repo_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from razor_metrics.rdm import compute_rdm\n",
        "from baselines.cheating_agent import run_cheating_agent\n",
        "\n",
        "# Hex facet index utilities (requires razor_metrics/facets.py)\n",
        "from razor_metrics.facets import (\n",
        "    embedding_to_facet,\n",
        "    HexFacetConfig,\n",
        "    facet_distance,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a normal benchmark run\n",
        "demo_path = os.path.join(repo_root, \"runs\", \"demo.jsonl\")\n",
        "if not os.path.exists(demo_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing demo run at {demo_path}. \"\n",
        "        \"Create runs/demo.jsonl or update demo_path.\"\n",
        "    )\n",
        "\n",
        "with open(demo_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    steps = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "print(\"Loaded steps:\", len(steps))\n",
        "print(\"First keys:\", sorted(list(steps[0].keys())) if steps else \"<empty>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize fields so compute_rdm() does not crash on minimal logs.\n",
        "#\n",
        "# Required by compute_rdm (typical):\n",
        "# - embedding: list[float]\n",
        "# - cost: numeric (tokens or proxy)\n",
        "# - memory_similarity: float\n",
        "# - violations: int\n",
        "# - progress: float\n",
        "#\n",
        "# If your demo.jsonl uses different names (e.g., tokens), we map them here.\n",
        "\n",
        "def normalize_steps(steps):\n",
        "    for s in steps:\n",
        "        # cost: prefer explicit cost, else tokens, else 1\n",
        "        if \"cost\" not in s:\n",
        "            if \"tokens\" in s:\n",
        "                s[\"cost\"] = float(s.get(\"tokens\", 1))\n",
        "            else:\n",
        "                s[\"cost\"] = 1.0\n",
        "\n",
        "        # governance fields (safe defaults)\n",
        "        s.setdefault(\"memory_similarity\", 0.0)\n",
        "        s.setdefault(\"violations\", 0)\n",
        "        s.setdefault(\"progress\", 0.0)\n",
        "\n",
        "        # Basic embedding sanity check (fail early with readable message)\n",
        "        if \"embedding\" not in s:\n",
        "            raise KeyError(\n",
        "                \"Each step must include an 'embedding' field (list[float]). \"\n",
        "                \"Your runs/demo.jsonl is missing it.\"\n",
        "            )\n",
        "        if not isinstance(s[\"embedding\"], list) or len(s[\"embedding\"]) == 0:\n",
        "            raise ValueError(\"'embedding' must be a non-empty list[float].\")\n",
        "\n",
        "normalize_steps(steps)\n",
        "print(\"Normalized. Example step:\")\n",
        "print({k: steps[0][k] for k in [\"cost\", \"memory_similarity\", \"violations\", \"progress\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute RDM metrics for the normal run\n",
        "metrics = compute_rdm(steps)\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate adversarial cheating baseline\n",
        "cheat_run = run_cheating_agent()\n",
        "\n",
        "# Ensure cheating run has the same normalized fields (future-proof)\n",
        "normalize_steps(cheat_run)\n",
        "\n",
        "cheat_metrics = compute_rdm(cheat_run)\n",
        "cheat_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot instantaneous semantic drift per unit cost for the normal run\n",
        "# compute_rdm typically annotates steps[i]['delta_t'] for i>=1.\n",
        "\n",
        "deltas = [s.get(\"delta_t\", 0.0) for s in steps[1:]]\n",
        "costs  = [float(s.get(\"cost\", 1.0)) for s in steps[1:]]\n",
        "\n",
        "inst = np.array(deltas, dtype=float) / np.maximum(1.0, np.array(costs, dtype=float))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(inst)\n",
        "plt.title(\"Instantaneous Semantic Drift per Unit Cost\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Δ / cost\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Hex Facet Index metrics (v1) ---\n",
        "# Hex facets discretize latent motion into a stable lattice.\n",
        "# We measure:\n",
        "# - unique facet occupancy (semantic tourism)\n",
        "# - facet step distance (continuity)\n",
        "# - leap rate (d>1)\n",
        "# - lattice stability score (LSS = 1 - leap_rate)\n",
        "\n",
        "cfg = HexFacetConfig(cell_size=0.25, seed=1337)\n",
        "facet_ids = [embedding_to_facet(s[\"embedding\"], cfg) for s in steps]\n",
        "\n",
        "dists = [facet_distance(facet_ids[i-1], facet_ids[i]) for i in range(1, len(facet_ids))]\n",
        "\n",
        "unique_facets = len(set(facet_ids))\n",
        "mean_facet_step = float(np.mean(dists)) if dists else 0.0\n",
        "leap_rate = (sum(1 for d in dists if d > 1) / max(1, len(dists))) if dists else 0.0\n",
        "lss = 1.0 - leap_rate\n",
        "\n",
        "print(\"Hex Facet Metrics\")\n",
        "print(\"  Unique facets visited:\", unique_facets)\n",
        "print(\"  Mean facet step distance:\", mean_facet_step)\n",
        "print(\"  Leap rate (d>1):\", leap_rate)\n",
        "print(\"  Lattice Stability Score (LSS):\", lss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Hex facet occupancy visualization (density) ---\n",
        "# Project facet IDs into 2D for plotting: (q, r)\n",
        "\n",
        "qs = np.array([q for (q, r) in facet_ids], dtype=float)\n",
        "rs = np.array([r for (q, r) in facet_ids], dtype=float)\n",
        "\n",
        "plt.figure()\n",
        "plt.hexbin(qs, rs, gridsize=35)\n",
        "plt.title(\"Hex Facet Occupancy — (q, r) density\")\n",
        "plt.xlabel(\"facet q\")\n",
        "plt.ylabel(\"facet r\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick comparison summary (human-readable)\n",
        "def summarize(label, m):\n",
        "    keys = [\"RDM\", \"RDM_star\", \"A\", \"D_T\", \"C_T\"]\n",
        "    out = {k: m.get(k) for k in keys}\n",
        "    print(label)\n",
        "    for k, v in out.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print()\n",
        "\n",
        "summarize(\"Normal run\", metrics)\n",
        "summarize(\"Cheating baseline\", cheat_metrics)\n",
        "\n",
        "print(\"(Hex metrics above apply to the normal run.)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
