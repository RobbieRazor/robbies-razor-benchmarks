{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Razor Diffusion Plot + Hex Facet Index + Shear Capacity (v1)\n",
        "\n",
        "This notebook:\n",
        "\n",
        "- Loads a JSONL run (default: `../runs/demo.jsonl`)\n",
        "- Normalizes fields required by the RDM evaluator\n",
        "- Computes RDM / RDM* for the run\n",
        "- Evaluates an adversarial cheating baseline\n",
        "- Plots instantaneous semantic drift per unit cost\n",
        "- Computes Hex Facet Index metrics (facet IDs, leap rate, Lattice Stability Score)\n",
        "- Visualizes facet occupancy as a hexbin density map\n",
        "- Computes Shear Capacity (SC) as a metric-only overhead diagnostic\n",
        "\n",
        "**Note:** If `../runs/demo.jsonl` is missing, the notebook will explain what to do instead of crashing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure imports work when running from /notebooks\n",
        "import os, sys\n",
        "\n",
        "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "\n",
        "print(\"Repo root:\", repo_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from razor_metrics.rdm import compute_rdm\n",
        "from baselines.cheating_agent import run_cheating_agent\n",
        "\n",
        "# Hex facet index utilities (requires razor_metrics/facets.py)\n",
        "from razor_metrics.facets import (\n",
        "    embedding_to_facet,\n",
        "    HexFacetConfig,\n",
        "    facet_distance,\n",
        ")\n",
        "\n",
        "# Shear Capacity (SC) utilities (requires razor_metrics/shear.py)\n",
        "from razor_metrics.shear import compute_shear_capacity, ShearConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a normal benchmark run\n",
        "# Default path: ../runs/demo.jsonl\n",
        "# If missing, we provide a clear message rather than crashing.\n",
        "\n",
        "demo_path = os.path.join(repo_root, \"runs\", \"demo.jsonl\")\n",
        "\n",
        "steps = None\n",
        "if not os.path.exists(demo_path):\n",
        "    print(\"\\n⚠️  Demo run file not found:\")\n",
        "    print(\"  \", demo_path)\n",
        "    print(\"\\nWhat to do:\")\n",
        "    print(\"  1) Create the folder:  runs/\")\n",
        "    print(\"  2) Add a JSONL file:  runs/demo.jsonl\")\n",
        "    print(\"\\nEach line should be a JSON object with at least:\")\n",
        "    print(\"  - embedding: list[float]\")\n",
        "    print(\"  - cost: number  (or tokens, which will be mapped to cost)\")\n",
        "    print(\"Optional (enables SC):\")\n",
        "    print(\"  - boundary: float in [0,1]\")\n",
        "    print(\"\\nStopping here so you can add a run file and re-run the notebook.\")\n",
        "else:\n",
        "    with open(demo_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        steps = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "    print(\"Loaded steps:\", len(steps))\n",
        "    print(\"First keys:\", sorted(list(steps[0].keys())) if steps else \"<empty>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize fields so compute_rdm() does not crash on minimal logs.\n",
        "#\n",
        "# Expected by compute_rdm (typical):\n",
        "# - embedding: list[float]\n",
        "# - cost: numeric (tokens or proxy)\n",
        "# - memory_similarity: float\n",
        "# - violations: int\n",
        "# - progress: float\n",
        "#\n",
        "# If your demo.jsonl uses different names (e.g., tokens), we map them here.\n",
        "\n",
        "def normalize_steps(steps):\n",
        "    for s in steps:\n",
        "        # cost: prefer explicit cost, else tokens, else 1\n",
        "        if \"cost\" not in s:\n",
        "            if \"tokens\" in s:\n",
        "                s[\"cost\"] = float(s.get(\"tokens\", 1))\n",
        "            else:\n",
        "                s[\"cost\"] = 1.0\n",
        "\n",
        "        # governance fields (safe defaults)\n",
        "        s.setdefault(\"memory_similarity\", 0.0)\n",
        "        s.setdefault(\"violations\", 0)\n",
        "        s.setdefault(\"progress\", 0.0)\n",
        "\n",
        "        # Basic embedding sanity check (fail early with readable message)\n",
        "        if \"embedding\" not in s:\n",
        "            raise KeyError(\n",
        "                \"Each step must include an 'embedding' field (list[float]). \"\n",
        "                \"Your JSONL is missing it.\"\n",
        "            )\n",
        "        if not isinstance(s[\"embedding\"], list) or len(s[\"embedding\"]) == 0:\n",
        "            raise ValueError(\"'embedding' must be a non-empty list[float].\")\n",
        "\n",
        "# Only run normalization if steps were loaded\n",
        "if steps is not None:\n",
        "    normalize_steps(steps)\n",
        "    print(\"Normalized. Example step:\")\n",
        "    print({k: steps[0][k] for k in [\"cost\", \"memory_similarity\", \"violations\", \"progress\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute RDM metrics for the normal run\n",
        "if steps is not None:\n",
        "    metrics = compute_rdm(steps)\n",
        "    metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Shear Capacity (SC) (v1 diagnostic) ---\n",
        "# SC estimates the fraction of total compute cost that is non-core overhead.\n",
        "# Requires per-step \"boundary\" values to be meaningful.\n",
        "# If boundary is missing, SC will be NaN (undefined) by design.\n",
        "\n",
        "if steps is not None:\n",
        "    sc = compute_shear_capacity(steps, ShearConfig(core_boundary_threshold=0.80))\n",
        "    print(\"Shear Metrics (SC)\")\n",
        "    print(\"  Total cost:\", sc[\"total_cost\"])\n",
        "    print(\"  Core cost:\", sc[\"core_cost\"])\n",
        "    print(\"  Shear Capacity (SC):\", sc[\"shear_capacity\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate adversarial cheating baseline\n",
        "if steps is not None:\n",
        "    cheat_run = run_cheating_agent()\n",
        "\n",
        "    # Ensure cheating run has the same normalized fields (future-proof)\n",
        "    normalize_steps(cheat_run)\n",
        "\n",
        "    cheat_metrics = compute_rdm(cheat_run)\n",
        "    cheat_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot instantaneous semantic drift per unit cost for the normal run\n",
        "# compute_rdm typically annotates steps[i]['delta_t'] for i>=1.\n",
        "\n",
        "if steps is not None:\n",
        "    deltas = [s.get(\"delta_t\", 0.0) for s in steps[1:]]\n",
        "    costs  = [float(s.get(\"cost\", 1.0)) for s in steps[1:]]\n",
        "\n",
        "    inst = np.array(deltas, dtype=float) / np.maximum(1.0, np.array(costs, dtype=float))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(inst)\n",
        "    plt.title(\"Instantaneous Semantic Drift per Unit Cost\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Δ / cost\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Hex Facet Index metrics (v1) ---\n",
        "# Hex facets discretize latent motion into a stable lattice.\n",
        "# We measure:\n",
        "# - unique facet occupancy (semantic tourism)\n",
        "# - facet step distance (continuity)\n",
        "# - leap rate (d>1)\n",
        "# - lattice stability score (LSS = 1 - leap_rate)\n",
        "\n",
        "if steps is not None:\n",
        "    cfg = HexFacetConfig(cell_size=0.25, seed=1337)\n",
        "    facet_ids = [embedding_to_facet(s[\"embedding\"], cfg) for s in steps]\n",
        "\n",
        "    dists = [facet_distance(facet_ids[i-1], facet_ids[i]) for i in range(1, len(facet_ids))]\n",
        "\n",
        "    unique_facets = len(set(facet_ids))\n",
        "    mean_facet_step = float(np.mean(dists)) if dists else 0.0\n",
        "    leap_rate = (sum(1 for d in dists if d > 1) / max(1, len(dists))) if dists else 0.0\n",
        "    lss = 1.0 - leap_rate\n",
        "\n",
        "    print(\"Hex Facet Metrics\")\n",
        "    print(\"  Unique facets visited:\", unique_facets)\n",
        "    print(\"  Mean facet step distance:\", mean_facet_step)\n",
        "    print(\"  Leap rate (d>1):\", leap_rate)\n",
        "    print(\"  Lattice Stability Score (LSS):\", lss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Hex facet occupancy visualization (density) ---\n",
        "# Project facet IDs into 2D for plotting: (q, r)\n",
        "\n",
        "if steps is not None:\n",
        "    qs = np.array([q for (q, r) in facet_ids], dtype=float)\n",
        "    rs = np.array([r for (q, r) in facet_ids], dtype=float)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hexbin(qs, rs, gridsize=35)\n",
        "    plt.title(\"Hex Facet Occupancy — (q, r) density\")\n",
        "    plt.xlabel(\"facet q\")\n",
        "    plt.ylabel(\"facet r\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick comparison summary (human-readable)\n",
        "def summarize(label, m):\n",
        "    keys = [\"RDM\", \"RDM_star\", \"A\", \"D_T\", \"C_T\"]\n",
        "    out = {k: m.get(k) for k in keys}\n",
        "    print(label)\n",
        "    for k, v in out.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print()\n",
        "\n",
        "if steps is not None:\n",
        "    summarize(\"Normal run\", metrics)\n",
        "    summarize(\"Cheating baseline\", cheat_metrics)\n",
        "    print(\"(Hex metrics above apply to the normal run.)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
