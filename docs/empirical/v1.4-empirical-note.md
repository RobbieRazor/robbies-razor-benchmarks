# v1.4 — Empirical Note: Depth-8 Recursion Stability vs Refresh Cadence

## Scope

This note reports early empirical results evaluating the hypothesis:

> Recursive stability under finite resources can exhibit non-monotonic behavior across memory–compute allocation regimes.

These results are exploratory and controlled. They do not constitute a formal proof. The goal is to observe structured drift patterns under repeated compression cascades.

---

## Protocol Summary

- **Recursion depth:** 8 steps  
- **Temperature:** 0 (deterministic)  
- **Regimes tested:**
  - **Compute-heavy:** SOURCE provided at every step
  - **Memory-heavy:** SOURCE only at step 1 (capsule-only thereafter)
  - **Balanced:** capsule every step + periodic SOURCE refresh
- **Balanced cadence sweep:**  
  - `{1,7}`  
  - `{1,4,7}`  
  - `{1,3,5,7}`
- **Output format per step:**
  - `[FACT LINES]` (fixed count)
  - capsule (8–12 bullets, ≤12 words each)
- **Scoring:** signature-token retention per canonical fact line (paraphrase-robust; IDs, numbers, thresholds, caps preserved)

---

# Results

---

## Fixture #3 — ID-Collision Heavy

### Scores

| Regime | Score |
|--------|-------|
| Compute-heavy | **20/20** |
| Balanced `{1,7}` | 16/20 |
| Balanced `{1,4,7}` | 16/20 |
| Balanced `{1,3,5,7}` | **18/20** |
| Memory-heavy | 16/20 |

### Observed Pattern

- Increasing refresh frequency improved retention under balanced policy:
  - 16 → 18 → 20 (monotonic with refresh frequency).
- Compute-heavy retained all collision-prone IDs and thresholds.
- Remaining errors under balanced were concentrated in calendar fields (start/end dates).
- Memory-heavy tied the lower balanced cadences (16/20).

### Interpretation (Collision-Heavy)

For near-identical IDs and numeric thresholds, more frequent refresh improved stability. No non-monotonic optimum was observed on this fixture.

---

## Fixture #2 — Constraint-Heavy

### Scores

| Regime | Score |
|--------|-------|
| Compute-heavy | **18/20** |
| Balanced `{1,7}` | 9/20 |
| Balanced `{1,4,7}` | **11/20** |
| Balanced `{1,3,5,7}` | 8/20 |
| Memory-heavy | 7/20 |

### Observed Pattern

- Compute-heavy again produced highest retention.
- Balanced outperformed memory-heavy at all cadences.
- The relationship between refresh frequency and retention was **non-monotonic**:
  - 9 → 11 → 8
- The intermediate cadence `{1,4,7}` performed best among balanced schedules.

### What Failed Most Often

Across balanced and memory-heavy regimes, the most perishable fact types were:

- Hard limits (token caps)
- Tooling constraints
- Capsule size constraints
- Stop rules
- Forbidden behaviors
- Acceptance metrics
- Failure mode labels
- Logging requirements

These were lost even under frequent refresh, suggesting guardrail-style constraints are structurally brittle under capsule compression.

---

# Cross-Fixture Synthesis

Across fixtures:

1. **Compute-heavy consistently achieved the highest retention.**
2. Balanced performance was **content-dependent**:
   - Collision-heavy → refresh frequency improved retention monotonically.
   - Constraint-heavy → intermediate refresh performed best; too-frequent refresh degraded retention.
3. Memory-heavy consistently underperformed compute-heavy and sometimes matched lower balanced cadences.

This suggests that refresh cadence interacts with content type rather than producing a universal optimal midpoint.

---

# Conservative Interpretation

The experiments do not support a universal non-monotonic stability optimum.

Instead, results indicate:

- Refresh cadence effects are **task-dependent**.
- Collision-prone structured numeric content benefits from frequent refresh.
- Constraint-dense guardrail content exhibits non-monotonic behavior under refresh variation.
- Even compute-heavy regimes may lose certain meta-constraints.

These findings are consistent with the broader hypothesis that recursive stability is shaped by interaction between compression, refresh policy, and fact-type structure.

---

# Limitations

- Single deterministic run per fixture (no replication).
- Single model tested.
- No statistical analysis.
- No explicit cost normalization beyond regime definitions.
- Capsule size fixed (8–12 bullets, ≤12 words).
- Depth fixed at 8.

This is an early-stage probe, not a conclusive validation.

---

# Next Steps

- Add 2–3 additional fixtures spanning different fact distributions.
- Replicate each sweep across multiple runs.
- Compare across model families.
- Track compute proxies (token count, call count) to better quantify memory–compute tradeoff.
- Test capsule-size sweeps alongside cadence sweeps.

---

## Status

v1.4 constitutes an early empirical note demonstrating:

- Reproducible depth-8 drift patterns
- Fixture-dependent refresh effects
- Non-monotonic cadence behavior under constraint-heavy conditions

Further replication required before general claims.


