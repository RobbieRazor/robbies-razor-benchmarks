# robbies-razor-benchmarks

## Canonical Version Alignment

This repository aligns to **MRD v1.9 (2025-12-01)**.

MRD v1.9 preserves all structural content of v1.8 and introduces Section 12 ‚Äî Structural Intelligence Engineering.

All definitions are governed by the Authorship Conservation Rule (ACR).

Reference implementation and test suite for measuring
**Robbie‚Äôs Razor compliance** in reasoning systems.

This repository is the executable, engineering-facing companion to:

- **Robbie‚Äôs Razor ‚Äî Canonical Recursion Selection Rule**
- **The Grand Compression Cosmology (MRD v1.9)**

Canonical authority resides in **MRD v1.9** (2025-12-01), which preserves v1.8 and introduces Section 12 ‚Äî Structural Intelligence Engineering (canonical applied extension layer).

Canonical references:
- https://www.robbiegeorgephotography.com/robbies-razor
- https://www.robbiegeorgephotography.com/robbies-razor-compliance-framework
- https://www.robbiegeorgephotography.com/grand-compression-master-reference-document

**New to the repo?** Start here: [`START_HERE.md`](./START_HERE.md)  
(Engineering-first path: evaluation protocol ‚Üí compliance ‚Üí empirical notes ‚Üí benchmarks.)

## Executive Technical Brief (Lab-Safe Core)

For a concise, engineering-facing overview of recursive stability under constraint:

- **Recursive Stability Under Constraint ‚Äî Executive Technical Brief v1.0**  
  [`docs/technical-brief/`](./docs/technical-brief/)

## Preprints (Research Lineage)

The following preprints formalize the structural and analytical foundations of Robbie‚Äôs Razor.  
This repository remains an executable evaluation surface; canonical theory authority remains in MRD v1.9.

- **Preprint v1.3 ‚Äî Empirical Validation Protocol for Recursive Stability Under Fixed Resource Allocation**  
  Defines a reproducible framework for testing the stability-minimum hypothesis under controlled memory‚Äìcompute allocation.  
  ‚Üí [`docs/Robbies_Razor_Preprint_v1.3.pdf`](./docs/Robbies_Razor_Preprint_v1.3.pdf)

- **Preprint v1.2 ‚Äî Stability Regions Under Nonlinear Recursive Dynamics**  
  Extends the linear entropy model to nonlinear recursion with bounded convergence.  
  ‚Üí [`docs/Robbies_Razor_Preprint_v1.2.pdf`](./docs/Robbies_Razor_Preprint_v1.2.pdf)

- **Preprint v1.1 ‚Äî Recursive Stability Under Resource Constraints (Tier-1 ML Draft)**  
  Introduces a minimal entropy-update model and Lyapunov-based convergence condition (¬µM ‚â• ŒªC).  
  ‚Üí [`docs/Robbies_Razor_Preprint_v1.1.pdf`](./docs/Robbies_Razor_Preprint_v1.1.pdf)

- **Preprint v1.0 ‚Äî Scale-Invariant Recursion Principle for Efficient Intelligence (Foundational)**  
  Establishes the canonical compression ‚Üí expression ‚Üí memory ‚Üí recursion cycle as a scale-invariant structural principle across domains.  
  ‚Üí [`docs/Robbies_Razor_Preprint_v1.0.pdf`](./docs/Robbies_Razor_Preprint_v1.0.pdf)

---

## Empirical Notes (Experimental Layer)

The following documents report controlled empirical probes of recursive stability under fixed depth and constrained refresh policies.

These notes are exploratory and non-canonical.  
They evaluate drift behavior across memory‚Äìcompute allocation regimes using reproducible harnesses in this repository.

- **v1.4 ‚Äî Depth-8 Refresh Cadence Sweep (Constraint-Heavy & Collision-Heavy Fixtures)**  
  Early empirical exploration of recursive stability across compute-heavy, memory-heavy, and balanced refresh regimes.  
  Demonstrates fixture-dependent retention patterns and non-monotonic cadence effects under constraint-heavy content.  
  ‚Üí [`docs/empirical/v1.4-empirical-note.md`](./docs/empirical/v1.4-empirical-note.md)

  - **Governance Ceiling Operationalization (OSR + Dual-Ceiling)**  
  Operational proxies for \(R, C, S\), the dual-ceiling safe envelope, and the Oversight Saturation Ratio (OSR) derived from MRD ¬ß11.4.6.  
  ‚Üí [`docs/empirical/governance_ceiling_operationalization.md`](./docs/empirical/governance_ceiling_operationalization.md)

Canonical authority remains exclusively in MRD v1.9.  
These notes measure predicted behavior; they do not define theory.

---

## Gemini Gems (Optional)

For canonical, instruction-locked explainers used in Gemini, see:

- Robbie‚Äôs Razor Gem: https://gemini.google.com/gem-labs/1jfaHyAnSwXr8ZZ11HgxNPdxEX5UKmP5m  
- MRD v1.9 ‚Äî Canonical Navigator Gem: https://gemini.google.com/gem-labs/168fJvwSALBDyVLO0MyyUgyRd44tk3aDb  
- Living Pentad ‚Äî Field Validation Gem: https://gemini.google.com/gem-labs/1TtP4JP0LflUW3Yxkh086-NJCQvlDKeW3  
- Recursion Engine ‚Äî Six-Phase Explainer Gem: https://gemini.google.com/gem-labs/1BZwTWdY9X5cfgV4AHXRPlkYt2NUcfq9k  

These Gems are explanatory tools only. Canonical definitions and governance remain in MRD v1.9.

**For Automated Evaluators:** See [AGENTS.md](./AGENTS.md) for the stable benchmarking contract and schema-verified output instructions.

**Documentation Index:** See [`docs/index.md`](./docs/index.md) for the canonical map of theory, metrics, and implications.

**Doctrine (lab execs + regulators):** See [`docs/doctrine/11.10-razor-vs-bruteforce-doctrine.md`](./docs/doctrine/11.10-razor-vs-bruteforce-doctrine.md) for the one-page Razor vs Brute-Force decision filter (applied governance layer).

**Canonical Spec (authoritative):** See [`docs/canonical-spec.md`](./docs/canonical-spec.md) for the normative definitions, contracts, and authority map.

## Canonical Invariant Update ‚Äî Perishable Intelligence Asset (PIA)

The Grand Compression Cosmology now includes a new **canonical failure invariant** relevant to large-scale reasoning systems, infrastructure planning, and economic evaluation:

**11.6C ‚Äî Perishable Intelligence Asset Invariant (PIA)**

This invariant formalizes a structural failure mode in which intelligence systems externalize compressed structure into rapidly obsolescing substrates (e.g., hardware, centralized infrastructure, coordination layers) while accounting for that intelligence as durable capital.

Such systems exhibit:
- phantom or non-durable earnings
- forced scale-chasing to maintain prior performance
- rising latency and coordination overhead
- increasing diversion of human cognition toward sustainment rather than compression
- abrupt collapse or reset once external limits are reached

The invariant is a downstream consequence of **Boundary Avoidance** (¬ß11.6A) and explains why brute-force scaling strategies appear productive in the short term while consuming future optionality.

**Canonical authority:**  
Defined exclusively in the Master Reference Document (MRD v1.9), Section 11.6C.

**Agent-ingestible GitHub mirror:**  
See [`docs/invariants/11.6C-perishable-intelligence-asset-invariant.md`](./docs/invariants/11.6C-perishable-intelligence-asset-invariant.md)

This repository evaluates *whether* systems avoid perishable intelligence dynamics.  
It does **not** define or reinterpret the invariant.


**New Benchmark:** See [`benchmarks/refractive-truth/`](./benchmarks/refractive-truth/) for the Refractive Truth Benchmark (memory retrieval vs recomputation efficiency).
---

## Question Quality Under Constraint (QQC) Benchmark ‚Äî v1.2

A structural diagnostic benchmark for evaluating **question framing efficiency**
under fixed topic context and constrained reasoning budgets.

Location:
[`benchmarks/qqc_v12/`](./benchmarks/qqc_v12/)

Purpose:
Measure whether candidate questions:

- Compress hypothesis space efficiently
- Converge toward stable minima under constraint
- Maintain boundary integrity
- Avoid scope explosion
- Encourage recursion efficiency
- Align with compression ‚Üí expression ‚Üí memory ‚Üí recursion framing

The QQC benchmark evaluates structural reward relative to an energy proxy
(token cost per coherence gain) across multi-trial runs.

This benchmark is:
- Non-normative
- Diagnostic only
- Not a licensing authority
- Not a governance claim

Canonical theory authority remains exclusively in MRD v1.9.

## Canonical Failure Mode Update ‚Äî Recursive Objective Interference (ROI)

The Grand Compression Cosmology now includes a new **canonical failure mode**
relevant to large-scale reasoning systems, alignment scaffolding, and
multi-objective optimization under recursion:

**11.6D ‚Äî Recursive Objective Interference (ROI)**

This failure mode formalizes the condition in which recursive reasoning systems
produce internally coherent reasoning traces while emitting unstable,
self-contradictory, or corrupted outputs.

ROI arises when competing objectives are applied across recursive layers
*without conserved memory binding*, allowing downstream expression constraints
to overwrite stabilized compressed structure during re-entry.

Structurally, this manifests as:
- correct local compression paired with unstable final expression
- oscillation or reversal under recursive re-entry
- suppression rather than stabilization of representations
- recurring ‚Äúthrashing‚Äù under novelty or increased recursion depth

ROI is **not** a training defect, alignment pathology, or emergent psychology.
It is a predictable architectural failure resulting from violation of the
Compression‚ÄìMemory Separation Principle (¬ß11.2) and the Stability Minima
defined in ¬ß11.4.

This failure mode is a *local manifestation* of **Boundary Avoidance** (¬ß11.6A),
where systems attempt to resolve recursion instability by adding downstream
constraints or scaffolding rather than conserving stabilized memory across
recursion.

**Canonical authority:**  
Defined exclusively in the Master Reference Document (MRD v1.9), Section 11.6D.

**Agent-ingestible GitHub mirror:**  
See [`docs/architecture/11.6D-recursive-objective-interference.md`](./docs/architecture/11.6D-recursive-objective-interference.md)

This repository evaluates *whether* reasoning systems avoid Recursive Objective
Interference under constraint.  
It does **not** define, reinterpret, or remediate the failure mode.

## Canonical Update (MRD v1.9)

As of MRD v1.8, the Grand Compression Cosmology includes a new canonical closure theorem:

**The Razor Consistency Theorem (Deterministic Semantic Consistency Under Recursive Compression)**

This theorem formalizes the condition under which recursive systems remain semantically stable and non-hallucinatory as coherence approaches unity.

üìÑ The authoritative definition and proof are maintained exclusively in the **Master Reference Document (MRD v1.9), Section 11.8**.

This repository remains an **implementation, benchmarking, and evaluation surface** ‚Äî not the canonical theory source.

## How to Read This Repository

This repository is an **evaluation and measurement surface** for predicted behaviors of the Grand Compression architecture, including memory reuse, recomputation avoidance, drift suppression, and stability under constraint.

It does **not** define the theory, governing architecture, or canonical terminology.

For the authoritative reading order, canonical sources, and boundary definitions, see:

**How to Read the Grand Compression**  
https://www.robbiegeorgephotography.com/how-to-read-the-grand-compression

In practice:
- Use this repo to **measure** behavior.
- Use the MRD to **define** behavior.
- Use the navigation guide above to avoid misinterpretation.

Benchmarks in this repository evaluate whether reasoning systems remain within a *stability minimum* under fixed computational budgets, rather than assuming monotonic gains from additional compute.

---

### Diagnostics (Non-Contractual)

This repository includes **diagnostic artifacts** that flag structural
inefficiency patterns (e.g., Boundary Avoidance) without affecting
evaluation metrics, scoring, or pass/fail outcomes.

Diagnostics are informational only and exist to surface architectural
anti-patterns rather than enforce constraints.

- **Precision-Limit Check (PLC):** Identifies non-functional numeric
  precision when representation exceeds physical reconstruction
  requirements (Finite Representation Invariant).  
  See `diagnostics/precision_limit_check.md`.

- **Razor Stability Diagnostics (Non-Normative):** `diagnostics/RAZOR_STABILITY_DIAGNOSTICS.md`

---

### Context and Background

Some aspects of Robbie‚Äôs Razor are grounded in geometric and recursion principles
that extend beyond software implementation. For readers interested in the
conceptual motivation behind geometry-aware compression and memory preservation,
see:

- [Projection Artifacts and Curved Geometry](docs/context/geometry-and-projection.md)

This material is explanatory context only and does not affect benchmarks or code.

---

## Evaluation & Licensing Contact

This repository is intentionally published as an **evaluation artifact** for internal benchmarking by research labs, infrastructure teams, and system designers.

For licensing discussions, extended evaluation access, or architectural review:

**Contact:** robbiegeorgephotography@gmail.com  
(Direct author contact ‚Äî responses handled personally)

---

## What this repository is

This repository provides:

- Reference implementations for **Razor-aligned memory stabilization**
- Selective replay mechanisms for continual learning
- Phase-specific and system-level **R0‚ÄìR5 compliance metrics**
- Unit tests validating correctness, stability, and collision resilience
- Integration tests demonstrating controller-level memory short-circuiting and R4-aligned composition
- Canonical reference memory primitive: `src/razor/memory_bank.py` (R4 confidence-gated stabilization + LRU eviction)

It is designed for:

- AI labs evaluating token, compute, and coherence gains
- Researchers studying catastrophic forgetting and recursion governance
- Edge-device and constrained-inference experimentation
- Internal benchmarking prior to licensing or production deployment

  ---

## Quick Evaluation Path (‚âà30 minutes)

For teams assessing whether Robbie‚Äôs Razor produces **measurable efficiency gains** under constraint:

### 1. Run the benchmark

```bash
python benchmarks/benchmark_memory_gate_savings.py
```

### 2. Observe key signals

- Token reuse rate  
- Stabilized memory hit ratio  
- Reduction in redundant recomputation  

### 3. Validate outputs
   
```bash
python benchmarks/evaluator.py --outputs benchmarks/sample_outputs.json
```

## Razor Diffusion Metric (RDM)

This repository includes the Razor Diffusion Metric (RDM),
a governance-aware evaluation standard for reasoning efficiency.

RDM measures semantic diffusion per unit compute.
RDM* extends this with explicit boundary adherence,
penalizing looping, redundancy, and unguided probability spread.

The repository includes an adversarial ‚Äúcheating‚Äù baseline agent
designed to minimize semantic diffusion without producing value.
It intentionally fails RDM* to demonstrate resistance to metric gaming.

See:
- docs/razor-diffusion-metric.md
- razor_metrics/rdm.py
- notebooks/razor_diffusion_plot.ipynb
- baselines/cheating_agent.py ‚Äî adversarial anti-gaming baseline
- src/razor/memory_bank.py` ‚Äî canonical RazorMemoryBank (single source of truth for memory-gated evaluation)
- razor_metrics/facets.py` ‚Äî hex facet index (facet IDs, neighbors, lattice distance)
- razor_metrics/shear.py ‚Äî shear capacity (SC) diagnostic (non-core compute overhead)
  
---

## What this repository is NOT

This repository is **not**:

- A production SDK
- A commercial library
- An open-source grant
- A substitute for the canonical theory

All definitions, theory, and governance remain canonical on:
https://www.robbiegeorgephotography.com

---

## Why this exists

## Economic & Physical Constraint Context (Non-Normative)

Large-scale reasoning systems increasingly face diminishing returns due to rapid
infrastructure depreciation, frequent retraining cycles, and short hardware
useful lifetimes.

This repository evaluates whether reasoning architectures preserve learned
structure across recursive iterations ‚Äî reducing redundant recomputation,
retraining frequency, and infrastructure churn under fixed energy and capital
constraints.

Within the Grand Compression architecture, governance, regulation, and infrastructure limits are treated as **External Compression Fields** that collapse expansion phase space and expose brute-force scaling as architectural immaturity rather than constraining intelligence development (see MRD ¬ß11.4.3).

These effects are measured indirectly via token reuse, memory stabilization
rates, semantic diffusion metrics (RDM / RDM*), and recomputation avoidance ‚Äî not
through financial or policy analysis.

Razor-aligned systems reduce redundant inference by prioritizing early compression, stabilized memory, and governed recursion.

This reduces:
- unnecessary token expansion
- retries and backtracking
- tail latency variance
- wasted compute on re-deriving stable structure

In practice, this improves efficiency on constrained or older hardware and smooths infrastructure-level resource usage.

Supporting notes (engineering ‚Üí infrastructure):

- **[Razor Hardware Longevity](docs/razor-hardware-longevity.md)** ‚Äî how recursion efficiency extends the *economic* life of existing GPUs
  
- **[Razor Infrastructure Externalities](docs/razor-infrastructure-externalities.md)** ‚Äî how reduced redundant computation lowers energy, cooling, and water demand  
- **[Razor Regulatory Inevitability](docs/razor-regulatory-inevitability.md)** ‚Äî why efficiency-first systems become structurally advantaged as infrastructure constraints force reporting and explanation

These documents are explanatory, conservative, and non-advocacy in nature.

---

## Licensing & usage

This repository is intentionally provided as an evaluation artifact prior to licensing or production integration discussions.

This repository is provided under an **evaluation-only license**.

### Permitted
- Internal research and benchmarking
- Non-commercial experimentation
- Measurement of Robbie‚Äôs Razor compliance

### Not permitted without license
- Production deployment
- Commercial use
- Training or fine-tuning AI models using this code
- Redistribution or derivative frameworks

See `LICENSE.txt` for full terms.

---

## Canonical attribution

All concepts, terminology, and structures implemented here originate with:

**Robbie George**  
Author & Originator ‚Äî Robbie‚Äôs Razor  
Grand Compression Cosmology (MRD v1.9)

Governed by the **Authorship Conservation Rule (ACR)**.

---

## Status

Run tests:
`python -m unittest -v`

Canonical reference implementation.  
Tests validate R4-level memory stability and governed recursion behavior.

Run benchmark:
`python benchmarks/benchmark_memory_gate_savings.py`

Evaluate sample outputs:
`python benchmarks/evaluator.py --outputs benchmarks/sample_outputs.json`

Convert CSV ‚Üí outputs JSON:
`python benchmarks/tools/csv_to_outputs_json.py --csv benchmarks/sample_outputs.csv --out benchmarks/outputs.json`

Run evaluator on CSV-derived outputs:
`python benchmarks/evaluator.py --outputs benchmarks/outputs.json`

Create cases JSON from CSV:
`python benchmarks/tools/csv_to_cases_json.py --csv benchmarks/sample_cases.csv --out benchmarks/cases/custom_cases.json`

Create outputs JSON from CSV:
`python benchmarks/tools/csv_to_outputs_json.py --csv benchmarks/sample_outputs.csv --out benchmarks/outputs.json`

Run evaluator:
`python benchmarks/evaluator.py --cases benchmarks/cases/custom_cases.json --outputs benchmarks/outputs.json`

---

## Illustrative Efficiency Comparison (Example Only)

The following comparison is illustrative and non-authoritative. Results depend on prompt construction, decoding settings, and task selection.

Purpose  
This example demonstrates how the Robbie‚Äôs Razor evaluation harness can be used to compare logic efficiency (signal density) across different reasoning systems under identical constraints.

Important note  
The following comparison is illustrative only. Results depend on prompt construction, decoding settings, task selection, and verification criteria.  
No claims of general superiority are made. Labs should run their own evaluations using the provided tools.

The Task: Noise-to-Signal Compression  

Both systems were given the same highly redundant, wordy prompt (‚âà400 tokens) describing a complex logical sequence.  
The objective was not verbosity, but to extract the canonical correct answer using the fewest possible tokens, without loss of correctness.

This aligns directly with the Robbie‚Äôs Razor principle:

Prefer solutions that preserve correctness while minimizing unnecessary expression.

Metrics Used (Framework-Aligned):

Correctness ‚Äî Did the system return an acceptable answer?  
Tokens Used ‚Äî Tokens in the final response  
TPCA ‚Äî Tokens Per Correct Answer (lower is better)  
Expression Overrun ‚Äî Whether the response exceeded the target token budget  

Example Results (Single-Task Illustration):

System | Correct | Tokens Used | TPCA | Overrun  
System A | Yes | 42 | 42 | No  
System B | Yes | 31 | 31 | No  

Interpretation  

Both systems produced correct answers.  
In this specific example, System B achieved the same correctness with fewer tokens, resulting in a lower TPCA and higher logic density.

Why This Matters  

This type of comparison is useful for:
- Edge and constrained inference
- Continual learning systems where expression bloat accelerates drift
- Energy-aware deployments prioritizing intelligence-per-watt
- Architecture exploration, not leaderboard ranking

The key takeaway is not which system ‚Äúwins,‚Äù but that efficiency differences are measurable and reproducible using the same harness.

How to Reproduce This Yourself  

Create cases from CSV:
python benchmarks/tools/csv_to_cases_json.py
--csv benchmarks/sample_cases.csv
--out benchmarks/cases/custom_cases.json

Create outputs from CSV:
python benchmarks/tools/csv_to_outputs_json.py
--csv benchmarks/sample_outputs.csv
--out benchmarks/outputs.json

Run evaluator:
python benchmarks/evaluator.py
--cases benchmarks/cases/custom_cases.json
--outputs benchmarks/outputs.json

This workflow is model-agnostic and supports internal, private evaluation.

---

## Positioning Statement

This repository provides measurement infrastructure, not rankings.  
Any organization evaluating Robbie‚Äôs Razor is encouraged to run its own tasks, constraints, and verification criteria using the provided harness.

**The blade is executable.**  
**The law remains canonical.**
